{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Community Health Agent",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Community Health Agent - Kaggle-ready single-file implementation\n",
        "# Paste this entire file into a Kaggle notebook cell and run.\n",
        "\n",
        "from __future__ import annotations\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import uuid\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "\n",
        "try:\n",
        "    import google.generativeai as genai  # type: ignore\n",
        "    GEMINI_SDK_AVAILABLE = True\n",
        "except Exception:\n",
        "    genai = None  # type: ignore\n",
        "    GEMINI_SDK_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from kaggle_secrets import UserSecretsClient  # type: ignore\n",
        "    KAGGLE_SECRETS_AVAILABLE = True\n",
        "except Exception:\n",
        "    UserSecretsClient = None  # type: ignore\n",
        "    KAGGLE_SECRETS_AVAILABLE = False\n",
        "\n",
        "def safe_print(*args, **kwargs):\n",
        "    print(*args, **kwargs)\n",
        "\n",
        "def _load_api_key() -> Optional[str]:\n",
        "    names = [\"AI_STUDIO_API_KEY\", \"CAPSTONE_PROJECT\", \"Capstone_Project\"]\n",
        "    for n in names:\n",
        "        v = os.environ.get(n)\n",
        "        if v:\n",
        "            return v\n",
        "    if KAGGLE_SECRETS_AVAILABLE:\n",
        "        try:\n",
        "            client = UserSecretsClient()\n",
        "            for key_name in [\"Capstone_Project\", \"CAPSTONE_PROJECT\", \"AI_STUDIO_API_KEY\"]:\n",
        "                try:\n",
        "                    v = client.get_secret(key_name)\n",
        "                    if v:\n",
        "                        return v\n",
        "                except Exception:\n",
        "                    continue\n",
        "        except Exception:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "API_KEY = _load_api_key()\n",
        "\n",
        "if GEMINI_SDK_AVAILABLE and API_KEY:\n",
        "    try:\n",
        "        genai.configure(api_key=API_KEY)\n",
        "        safe_print(\"[LLM] Gemini SDK configured.\")\n",
        "    except Exception as e:\n",
        "        safe_print(\"[LLM] Failed to configure Gemini SDK, falling back to mock mode:\", e)\n",
        "        GEMINI_SDK_AVAILABLE = False\n",
        "else:\n",
        "    if not GEMINI_SDK_AVAILABLE:\n",
        "        safe_print(\"[LLM] Gemini SDK not installed; running in mock mode.\")\n",
        "    else:\n",
        "        safe_print(\"[LLM] API key not found; running in mock mode.\")\n",
        "    GEMINI_SDK_AVAILABLE = False\n",
        "\n",
        "ADVISOR_MODEL = \"gemini-2.5-pro\"\n",
        "VALIDATOR_MODEL = \"gemini-2.5-pro\"\n",
        "EMBEDDING_MODEL = \"text-embedding-004\"\n",
        "DEFAULT_TEMPERATURE = 0.2\n",
        "DEFAULT_MAX_OUTPUT_TOKENS = 512\n",
        "\n",
        "class LLMClient:\n",
        "    def __init__(self, model: str, temperature: float = DEFAULT_TEMPERATURE, max_output_tokens: int = DEFAULT_MAX_OUTPUT_TOKENS):\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "        self.max_output_tokens = max_output_tokens\n",
        "        self.online = GEMINI_SDK_AVAILABLE\n",
        "\n",
        "    def generate(self, prompt: str) -> Dict[str, Any]:\n",
        "        if self.online:\n",
        "            try:\n",
        "                if hasattr(genai, \"responses\") and hasattr(genai.responses, \"create\"):\n",
        "                    r = genai.responses.create(model=self.model, input=prompt, temperature=self.temperature, max_output_tokens=self.max_output_tokens)\n",
        "                    text = None\n",
        "                    try:\n",
        "                        output = getattr(r, \"output\", None)\n",
        "                        if output and len(output) > 0:\n",
        "                            first = output[0]\n",
        "                            if isinstance(first, dict):\n",
        "                                content = first.get(\"content\")\n",
        "                                if content and len(content) > 0 and isinstance(content[0], dict) and \"text\" in content[0]:\n",
        "                                    text = content[0][\"text\"]\n",
        "                            else:\n",
        "                                try:\n",
        "                                    text = first.content[0].text  # type: ignore\n",
        "                                except Exception:\n",
        "                                    pass\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                    text = text or getattr(r, \"output_text\", None) or str(r)\n",
        "                    return {\"text\": str(text), \"structured\": None}\n",
        "                if hasattr(genai, \"generate_text\"):\n",
        "                    r = genai.generate_text(model=self.model, prompt=prompt, temperature=self.temperature, max_output_tokens=self.max_output_tokens)\n",
        "                    text = getattr(r, \"text\", None) or str(r)\n",
        "                    return {\"text\": str(text), \"structured\": None}\n",
        "                if hasattr(genai, \"generate\"):\n",
        "                    r = genai.generate(model=self.model, prompt=prompt)\n",
        "                    text = getattr(r, \"content\", None) or getattr(r, \"text\", None) or str(r)\n",
        "                    return {\"text\": str(text), \"structured\": None}\n",
        "            except Exception as e:\n",
        "                safe_print(\"[LLM] SDK call failed, using mock response:\", e)\n",
        "                return self._mock_response(prompt)\n",
        "        return self._mock_response(prompt)\n",
        "\n",
        "    def _mock_response(self, prompt: str) -> Dict[str, Any]:\n",
        "        lower = prompt.lower()\n",
        "        if \"chest pain\" in lower or \"difficulty breathing\" in lower:\n",
        "            return {\"text\": \"I detect potentially serious symptoms. Please seek urgent medical attention.\", \"structured\": {\"severity\": \"high\", \"action\": \"escalate\"}}\n",
        "        if \"fever\" in lower and (\"3 days\" in lower or \"72 hours\" in lower or \"72hrs\" in lower):\n",
        "            return {\"text\": \"Persistent fever (>72 hours) should be evaluated by a clinician.\", \"structured\": {\"severity\": \"medium\", \"action\": \"see_clinic\"}}\n",
        "        return {\"text\": \"Based on your description: rest, hydrate, monitor symptoms. Seek care if worsening.\", \"structured\": {\"severity\": \"low\", \"action\": \"self_care\"}}\n",
        "\n",
        "class EmbeddingClient:\n",
        "    def __init__(self, model: str = EMBEDDING_MODEL):\n",
        "        self.model = model\n",
        "        self.online = GEMINI_SDK_AVAILABLE\n",
        "\n",
        "    def embed(self, texts: List[str]) -> List[List[float]]:\n",
        "        if self.online:\n",
        "            try:\n",
        "                if hasattr(genai, \"embeddings\") and hasattr(genai.embeddings, \"create\"):\n",
        "                    r = genai.embeddings.create(model=self.model, input=texts)\n",
        "                    data = getattr(r, \"data\", None) or (r.get(\"data\") if isinstance(r, dict) else None)\n",
        "                    if data:\n",
        "                        emb = []\n",
        "                        for d in data:\n",
        "                            vec = d.get(\"embedding\") if isinstance(d, dict) else getattr(d, \"embedding\", None)\n",
        "                            emb.append(list(vec))\n",
        "                        return emb\n",
        "                if hasattr(genai, \"generate_embeddings\"):\n",
        "                    r = genai.generate_embeddings(model=self.model, input=texts)\n",
        "                    data = getattr(r, \"data\", None) or (r.get(\"data\") if isinstance(r, dict) else None)\n",
        "                    if data:\n",
        "                        emb = []\n",
        "                        for d in data:\n",
        "                            vec = d.get(\"embedding\") if isinstance(d, dict) else getattr(d, \"embedding\", None)\n",
        "                            emb.append(list(vec))\n",
        "                        return emb\n",
        "            except Exception as e:\n",
        "                safe_print(\"[Embed] SDK call failed, using mock vectors:\", e)\n",
        "                return [self._mock_vector(t) for t in texts]\n",
        "        return [self._mock_vector(t) for t in texts]\n",
        "\n",
        "    def _mock_vector(self, text: str) -> List[float]:\n",
        "        vec = [float((ord(c) % 97) / 97.0) for c in text[:64]]\n",
        "        vec = (vec + [0.0] * 32)[:32]\n",
        "        return vec\n",
        "\n",
        "@dataclass\n",
        "class MemoryRecord:\n",
        "    user_id: str\n",
        "    content: str\n",
        "    created_at: str = field(default_factory=lambda: time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()))\n",
        "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
        "    id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
        "\n",
        "class MemoryAgent:\n",
        "    def __init__(self, use_embeddings: bool = True):\n",
        "        self.store: List[MemoryRecord] = []\n",
        "        self.use_embeddings = use_embeddings and GEMINI_SDK_AVAILABLE\n",
        "        self.embedding_client = EmbeddingClient() if self.use_embeddings else None\n",
        "        self.embeddings_index: List[List[float]] = []\n",
        "\n",
        "    def add(self, user_id: str, content: str, metadata: Optional[Dict[str, Any]] = None) -> str:\n",
        "        rec = MemoryRecord(user_id=user_id, content=content, metadata=metadata or {})\n",
        "        self.store.append(rec)\n",
        "        if self.use_embeddings and self.embedding_client:\n",
        "            vecs = self.embedding_client.embed([content])\n",
        "            if vecs:\n",
        "                self.embeddings_index.append(vecs[0])\n",
        "            else:\n",
        "                self.embeddings_index.append([0.0] * 32)\n",
        "        safe_print(f\"[MemoryAgent] Stored record {rec.id} for user {user_id}\")\n",
        "        return rec.id\n",
        "\n",
        "    def query(self, user_id: str, keywords: List[str], k: int = 5) -> List[MemoryRecord]:\n",
        "        if self.use_embeddings and keywords and self.embedding_client and self.embeddings_index:\n",
        "            q = \" \".join(keywords)\n",
        "            qv = self.embedding_client.embed([q])[0]\n",
        "            scores: List[Tuple[float, MemoryRecord]] = []\n",
        "            for rec, vec in zip(self.store, self.embeddings_index):\n",
        "                if rec.user_id != user_id:\n",
        "                    continue\n",
        "                score = self._cosine_similarity(qv, vec)\n",
        "                scores.append((score, rec))\n",
        "            scores.sort(key=lambda x: x[0], reverse=True)\n",
        "            return [r for _, r in scores[:k]]\n",
        "        scores: List[Tuple[float, MemoryRecord]] = []\n",
        "        klower = [w.lower() for w in keywords]\n",
        "        for rec in self.store:\n",
        "            if rec.user_id != user_id:\n",
        "                continue\n",
        "            score = 0\n",
        "            txt = rec.content.lower()\n",
        "            for kw in klower:\n",
        "                if kw in txt:\n",
        "                    score += 1\n",
        "            if score > 0:\n",
        "                scores.append((score, rec))\n",
        "        scores.sort(key=lambda x: x[0], reverse=True)\n",
        "        res = [r for _, r in scores[:k]]\n",
        "        safe_print(f\"[MemoryAgent] Query for {keywords} returned {len(res)} records\")\n",
        "        return res\n",
        "\n",
        "    def get_recent(self, user_id: str, k: int = 5) -> List[MemoryRecord]:\n",
        "        recs = [r for r in self.store if r.user_id == user_id]\n",
        "        recs.sort(key=lambda r: r.created_at, reverse=True)\n",
        "        return recs[:k]\n",
        "\n",
        "    def _cosine_similarity(self, a: List[float], b: List[float]) -> float:\n",
        "        import math\n",
        "        num = sum(x * y for x, y in zip(a, b))\n",
        "        denom_a = math.sqrt(sum(x * x for x in a))\n",
        "        denom_b = math.sqrt(sum(y * y for y in b))\n",
        "        if denom_a == 0 or denom_b == 0:\n",
        "            return 0.0\n",
        "        return num / (denom_a * denom_b)\n",
        "\n",
        "class SymptomCheckerTool:\n",
        "    def __init__(self):\n",
        "        self.knowledge = [\n",
        "            {\"conditions\": [\"fever\", \"cough\"], \"diagnosis\": \"Viral respiratory infection\", \"advice\": \"rest, hydrate, paracetamol if needed\", \"severity\": \"low\"},\n",
        "            {\"conditions\": [\"fever\", \"rash\"], \"diagnosis\": \"Possible measles or viral exanthem\", \"advice\": \"seek clinic evaluation\", \"severity\": \"medium\"},\n",
        "            {\"conditions\": [\"chest pain\", \"sweating\"], \"diagnosis\": \"Possible cardiac event\", \"advice\": \"seek emergency care\", \"severity\": \"high\"},\n",
        "            {\"conditions\": [\"shortness of breath\", \"wheezing\"], \"diagnosis\": \"Possible asthma exacerbation\", \"advice\": \"seek urgent care\", \"severity\": \"high\"},\n",
        "            {\"conditions\": [\"diarrhea\", \"dehydration\"], \"diagnosis\": \"Gastroenteritis\", \"advice\": \"oral rehydration\", \"severity\": \"medium\"},\n",
        "        ]\n",
        "\n",
        "    def check(self, symptoms: List[str]) -> Dict[str, Any]:\n",
        "        if not symptoms:\n",
        "            return {\"diagnosis\": \"Unknown\", \"advice\": \"Provide more details or seek clinician\", \"severity\": \"unknown\"}\n",
        "        symset = set(s.lower() for s in symptoms)\n",
        "        results = []\n",
        "        for rule in self.knowledge:\n",
        "            rule_conditions = set(rule[\"conditions\"])\n",
        "            if symset & rule_conditions:\n",
        "                overlap = len(symset & rule_conditions)\n",
        "                results.append((overlap, rule))\n",
        "        if not results:\n",
        "            return {\"diagnosis\": \"Unknown\", \"advice\": \"Provide more details or seek clinician\", \"severity\": \"unknown\"}\n",
        "        results.sort(key=lambda x: x[0], reverse=True)\n",
        "        top = results[0][1]\n",
        "        return {\"diagnosis\": top[\"diagnosis\"], \"advice\": top[\"advice\"], \"severity\": top[\"severity\"]}\n",
        "\n",
        "class ValidatorAgent:\n",
        "    def __init__(self, symptom_tool: SymptomCheckerTool, model: str = VALIDATOR_MODEL):\n",
        "        self.tool = symptom_tool\n",
        "        self.client = LLMClient(model)\n",
        "\n",
        "    def validate(self, user_text: str, proposed_action: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        lower = user_text.lower()\n",
        "        if any(w in lower for w in [\"chest pain\", \"severe chest pain\", \"crushing pain\", \"difficulty breathing\"]):\n",
        "            return {\"ok\": False, \"reason\": \"High-risk symptom detected (heuristic)\", \"recommendation\": \"escalate\"}\n",
        "        known = set(sum([r[\"conditions\"] for r in self.tool.knowledge], []))\n",
        "        tokens = [t.strip(\".,!?\") for t in user_text.lower().split()]\n",
        "        found = [t for t in tokens if t in known]\n",
        "        if found:\n",
        "            chk = self.tool.check(found)\n",
        "            if chk.get(\"severity\") == \"high\":\n",
        "                return {\"ok\": False, \"reason\": \"Tool suggests high severity\", \"recommendation\": \"escalate\"}\n",
        "        if GEMINI_SDK_AVAILABLE:\n",
        "            prompt = \"Classify the following patient text into severity: low, medium, high.\\nText: \" + user_text + \"\\nReturn a JSON object like: {\\\"severity\\\": \\\"low|medium|high\\\", \\\"note\\\": \\\"...\\\" }\"\n",
        "            resp = self.client.generate(prompt)\n",
        "            try:\n",
        "                txt = resp.get(\"text\", \"\")\n",
        "                low = \"low\" in txt.lower()\n",
        "                med = \"medium\" in txt.lower()\n",
        "                high = \"high\" in txt.lower()\n",
        "                if high and not med:\n",
        "                    return {\"ok\": False, \"reason\": \"Validator model suggests high severity\", \"recommendation\": \"escalate\"}\n",
        "                if med and not high:\n",
        "                    return {\"ok\": True, \"reason\": \"Validator model suggests medium severity\", \"recommendation\": \"see_clinic\"}\n",
        "            except Exception:\n",
        "                pass\n",
        "        return {\"ok\": True, \"reason\": \"No high-risk indicators\", \"recommendation\": \"safe\"}\n",
        "\n",
        "class SchedulerAgent:\n",
        "    def __init__(self):\n",
        "        self.tasks: Dict[str, Dict[str, Any]] = {}\n",
        "\n",
        "    def schedule(self, user_id: str, message: str, delay_seconds: int) -> str:\n",
        "        task_id = str(uuid.uuid4())\n",
        "        run_at = time.time() + max(0, int(delay_seconds))\n",
        "        self.tasks[task_id] = {\"user_id\": user_id, \"message\": message, \"run_at\": run_at}\n",
        "        safe_print(f\"[Scheduler] Scheduled reminder {task_id} in {delay_seconds}s\")\n",
        "        return task_id\n",
        "\n",
        "    def run_pending(self, current_time: Optional[float] = None) -> int:\n",
        "        \"\"\"Run all pending tasks that are due. Returns count of executed tasks.\"\"\"\n",
        "        now = current_time if current_time is not None else time.time()\n",
        "        to_run = [tid for tid, t in list(self.tasks.items()) if t[\"run_at\"] <= now]\n",
        "        for tid in to_run:\n",
        "            task = self.tasks.pop(tid, None)\n",
        "            if task:\n",
        "                safe_print(f\"[Reminder for {task['user_id']}] {task['message']}\")\n",
        "        return len(to_run)\n",
        "\n",
        "    def next_run_in(self) -> Optional[float]:\n",
        "        if not self.tasks:\n",
        "            return None\n",
        "        now = time.time()\n",
        "        next_run = min(t[\"run_at\"] for t in self.tasks.values())\n",
        "        return max(0.0, next_run - now)\n",
        "\n",
        "class AdvisorAgent:\n",
        "    def __init__(self, memory: MemoryAgent, validator: ValidatorAgent, scheduler: SchedulerAgent, symptom_tool: SymptomCheckerTool, model: str = ADVISOR_MODEL):\n",
        "        self.memory = memory\n",
        "        self.validator = validator\n",
        "        self.scheduler = scheduler\n",
        "        self.symptom_tool = symptom_tool\n",
        "        self.client = LLMClient(model)\n",
        "\n",
        "    def _extract_keywords(self, text: str) -> List[str]:\n",
        "        tokens = [t.strip(\".,!?()\") for t in text.lower().split()]\n",
        "        return [t for t in tokens if len(t) > 2][:10]\n",
        "\n",
        "    def _ask_clarifying(self, user_text: str) -> Optional[str]:\n",
        "        lower = user_text.lower()\n",
        "        if any(w in lower for w in [\"chest pain\", \"difficulty breathing\", \"severe chest pain\", \"crushing pain\", \"sweating\"]):\n",
        "            return None\n",
        "        keywords = self._extract_keywords(user_text)\n",
        "        if \"pain\" in keywords and \"where\" not in user_text.lower():\n",
        "            return \"Can you tell me where the pain is located and how severe it is (1-10)?\"\n",
        "        if \"fever\" in keywords and not any(w in user_text.lower() for w in [\"days\", \"hours\", \"duration\"]):\n",
        "            return \"How long have you had the fever? (e.g., 2 days, 12 hours)\"\n",
        "        return None\n",
        "\n",
        "    def handle(self, user_id: str, user_text: str) -> Dict[str, Any]:\n",
        "        safe_print(f\"[Advisor] Received from {user_id}: {user_text}\")\n",
        "        self.memory.add(user_id=user_id, content=user_text, metadata={\"role\": \"user_input\"})\n",
        "        clar = self._ask_clarifying(user_text)\n",
        "        if clar:\n",
        "            self.memory.add(user_id=user_id, content=clar, metadata={\"role\": \"clarifying_question\"})\n",
        "            return {\"type\": \"clarify\", \"message\": clar}\n",
        "        known_symptoms = set(sum([r[\"conditions\"] for r in self.symptom_tool.knowledge], []))\n",
        "        tokens = [t.strip(\".,!?()\") for t in user_text.lower().split()]\n",
        "        symptoms = [t for t in tokens if t in known_symptoms]\n",
        "        symptom_result = self.symptom_tool.check(symptoms) if symptoms else {\"diagnosis\": \"Unknown\", \"advice\": \"Please provide more details\", \"severity\": \"unknown\"}\n",
        "        safe_print(f\"[Advisor] Symptom tool result: {symptom_result}\")\n",
        "        prompt = (\n",
        "            \"User reported: \" + user_text + \"\\n\"\n",
        "            + \"Tool says: \" + json.dumps(symptom_result) + \"\\n\"\n",
        "            + \"Provide concise, empathetic advice and next steps. Return a short JSON with fields: message, severity, action.\"\n",
        "        )\n",
        "        llm_resp = self.client.generate(prompt)\n",
        "        validation = self.validator.validate(user_text, llm_resp.get(\"structured\", {}))\n",
        "        safe_print(f\"[Advisor] Validation: {validation}\")\n",
        "        if not validation.get(\"ok\"):\n",
        "            message = \"I detect potentially serious symptoms. Please seek urgent medical attention or call emergency services.\"\n",
        "            self.memory.add(user_id=user_id, content=message, metadata={\"role\": \"escalation\"})\n",
        "            return {\"type\": \"escalate\", \"message\": message, \"recommendation\": validation.get(\"recommendation\")}\n",
        "        text = llm_resp.get(\"text\", \"\")\n",
        "        parsed = None\n",
        "        try:\n",
        "            parsed = json.loads(text)\n",
        "        except Exception:\n",
        "            parsed = None\n",
        "        final_message = parsed.get(\"message\") if isinstance(parsed, dict) and parsed.get(\"message\") else text\n",
        "        severity = parsed.get(\"severity\") if isinstance(parsed, dict) and parsed.get(\"severity\") else symptom_result.get(\"severity\")\n",
        "        final = {\n",
        "            \"type\": \"advice\",\n",
        "            \"message\": final_message,\n",
        "            \"diagnosis\": symptom_result.get(\"diagnosis\"),\n",
        "            \"severity\": severity,\n",
        "            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n",
        "        }\n",
        "        self.memory.add(user_id=user_id, content=json.dumps(final), metadata={\"role\": \"agent_response\"})\n",
        "        return final\n",
        "\n",
        "    def set_reminder(self, user_id: str, message: str, delay_seconds: int) -> str:\n",
        "        return self.scheduler.schedule(user_id=user_id, message=message, delay_seconds=delay_seconds)\n",
        "\n",
        "def demo_conversation():\n",
        "    safe_print(\"Starting demo...\")\n",
        "\n",
        "    memory = MemoryAgent(use_embeddings=True)\n",
        "    symptom_tool = SymptomCheckerTool()\n",
        "    validator = ValidatorAgent(symptom_tool)\n",
        "    scheduler = SchedulerAgent()\n",
        "    advisor = AdvisorAgent(memory, validator, scheduler, symptom_tool)\n",
        "\n",
        "    user_id = \"user_001\"\n",
        "\n",
        "    user_msgs = [\n",
        "        \"I have a fever and cough.\",\n",
        "        \"It's been about 2 days and I also feel a bit tired.\",\n",
        "        \"I also have chest pain sometimes while breathing.\",\n",
        "    ]\n",
        "\n",
        "    for msg in user_msgs:\n",
        "        safe_print(f\"\\n> User: {msg}\")\n",
        "        resp = advisor.handle(user_id, msg)\n",
        "\n",
        "        if resp[\"type\"] == \"clarify\":\n",
        "            safe_print(f\"Agent (clarify): {resp['message']}\")\n",
        "            followup = \"Pain is in my chest and rating 5/10\"\n",
        "            safe_print(f\"User replies to clarifying Q: {followup}\")\n",
        "            resp2 = advisor.handle(user_id, followup)\n",
        "            safe_print(f\"Agent: {resp2['message']}\")\n",
        "\n",
        "        elif resp[\"type\"] == \"escalate\":\n",
        "            safe_print(f\"Agent (ESCALATE): {resp['message']}\")\n",
        "\n",
        "        else:\n",
        "            safe_print(f\"Agent: {resp['message']}\")\n",
        "\n",
        "    safe_print(\"\\n\\nScheduling follow-up reminders...\")\n",
        "\n",
        "    r1 = advisor.set_reminder(\n",
        "        user_id,\n",
        "        \"Please check your temperature again in 2 hours.\",\n",
        "        delay_seconds=2\n",
        "    )\n",
        "\n",
        "    r2 = advisor.set_reminder(\n",
        "        user_id,\n",
        "        \"Monitor your breathing and report any worsening symptoms in 6 hours.\",\n",
        "        delay_seconds=6\n",
        "    )\n",
        "\n",
        "    r3 = advisor.set_reminder(\n",
        "        user_id,\n",
        "        \"24-hour follow-up: How are your symptoms today?\",\n",
        "        delay_seconds=24\n",
        "    )\n",
        "\n",
        "    safe_print(\"Reminders scheduled:\", r1, r2, r3)\n",
        "\n",
        "    safe_print(\"\\n\\nRunning scheduler (simulated time)...\\n\")\n",
        "\n",
        "    future_time = time.time() + 999999\n",
        "    executed_count = scheduler.run_pending(current_time=future_time)\n",
        "    safe_print(f\"\\nExecuted {executed_count} reminders\")\n",
        "\n",
        "    safe_print(\"\\nDemo finished.\")\n",
        "\n",
        "def test_scheduler_behavior():\n",
        "    safe_print(\"\\n\\nRunning scheduler tests...\")\n",
        "    sched = SchedulerAgent()\n",
        "    id1 = sched.schedule(\"u1\", \"Immediate reminder\", delay_seconds=0)\n",
        "    id2 = sched.schedule(\"u1\", \"Delayed reminder\", delay_seconds=1)\n",
        "    executed1 = sched.run_pending()\n",
        "    assert executed1 >= 1, \"Expected at least 1 executed task (immediate)\"\n",
        "    safe_print(\"[Test] First run_pending executed:\", executed1)\n",
        "    time.sleep(1.2)\n",
        "    executed2 = sched.run_pending()\n",
        "    assert executed2 >= 1, \"Expected delayed task to execute\"\n",
        "    safe_print(\"[Test] Second run_pending executed:\", executed2)\n",
        "    safe_print(\"Scheduler tests passed.\")\n",
        "\n",
        "def test_advisor_flow():\n",
        "    safe_print(\"\\n\\nRunning advisor flow test...\")\n",
        "    mem = MemoryAgent(use_embeddings=False)\n",
        "    st = SymptomCheckerTool()\n",
        "    val = ValidatorAgent(st)\n",
        "    sched = SchedulerAgent()\n",
        "    adv = AdvisorAgent(mem, val, sched, st)\n",
        "    r1 = adv.handle(\"tester\", \"I have fever and cough for 1 day\")\n",
        "    assert r1[\"type\"] in (\"advice\", \"clarify\"), \"Advisor should return advice or ask to clarify\"\n",
        "    safe_print(\"[Test] Advisor returned type:\", r1[\"type\"])\n",
        "    r2 = adv.handle(\"tester\", \"I have chest pain and sweating\")\n",
        "    assert r2[\"type\"] == \"escalate\", \"Advisor should escalate on chest pain\"\n",
        "    safe_print(\"[Test] Advisor escalated as expected\")\n",
        "    safe_print(\"Advisor tests passed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo_conversation()\n",
        "    test_scheduler_behavior()\n",
        "    test_advisor_flow()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T10:04:34.114527Z",
          "iopub.execute_input": "2025-11-27T10:04:34.115782Z",
          "iopub.status.idle": "2025-11-27T10:04:35.525757Z",
          "shell.execute_reply.started": "2025-11-27T10:04:34.115743Z",
          "shell.execute_reply": "2025-11-27T10:04:35.524723Z"
        },
        "id": "nfPXBUphKk_w",
        "outputId": "7928f748-ce27-48cb-d7d5-a4e81c012cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[LLM] Gemini SDK configured.\nStarting demo...\n\n> User: I have a fever and cough.\n[Advisor] Received from user_001: I have a fever and cough.\n[MemoryAgent] Stored record 371541ce-c0bf-4fe8-802b-95fa878ab42d for user user_001\n[MemoryAgent] Stored record 7a8cad3b-03e6-4c0b-b022-f8010a952701 for user user_001\nAgent (clarify): How long have you had the fever? (e.g., 2 days, 12 hours)\nUser replies to clarifying Q: Pain is in my chest and rating 5/10\n[Advisor] Received from user_001: Pain is in my chest and rating 5/10\n[MemoryAgent] Stored record d795287e-b3e9-4cbe-97c2-354ac96ea0a8 for user user_001\n[MemoryAgent] Stored record 9588cda7-ab2b-4a24-bf5a-33bed9fbdabf for user user_001\nAgent: Can you tell me where the pain is located and how severe it is (1-10)?\n\n> User: It's been about 2 days and I also feel a bit tired.\n[Advisor] Received from user_001: It's been about 2 days and I also feel a bit tired.\n[MemoryAgent] Stored record 3eaf507b-032e-4e6b-9227-1f9a5fad0a8c for user user_001\n[Advisor] Symptom tool result: {'diagnosis': 'Unknown', 'advice': 'Please provide more details', 'severity': 'unknown'}\n[Advisor] Validation: {'ok': True, 'reason': 'No high-risk indicators', 'recommendation': 'safe'}\n[MemoryAgent] Stored record 72aed57a-81de-433e-84c0-b49d10238cce for user user_001\nAgent: Based on your description: rest, hydrate, monitor symptoms. Seek care if worsening.\n\n> User: I also have chest pain sometimes while breathing.\n[Advisor] Received from user_001: I also have chest pain sometimes while breathing.\n[MemoryAgent] Stored record 33e1dd7a-ae2b-48e9-af0f-08eac9dbb57a for user user_001\n[Advisor] Symptom tool result: {'diagnosis': 'Unknown', 'advice': 'Please provide more details', 'severity': 'unknown'}\n[Advisor] Validation: {'ok': False, 'reason': 'High-risk symptom detected (heuristic)', 'recommendation': 'escalate'}\n[MemoryAgent] Stored record e494e3b4-f6fb-49d2-8d5f-aa260f942825 for user user_001\nAgent (ESCALATE): I detect potentially serious symptoms. Please seek urgent medical attention or call emergency services.\n\n\nScheduling follow-up reminders...\n[Scheduler] Scheduled reminder 35fbff46-bf16-48a0-b81c-e05450f0b603 in 2s\n[Scheduler] Scheduled reminder f59b8553-aea6-4323-b580-6e7a54f787f6 in 6s\n[Scheduler] Scheduled reminder dc1cec1b-90c2-4493-9ea6-f89bb72c8721 in 24s\nReminders scheduled: 35fbff46-bf16-48a0-b81c-e05450f0b603 f59b8553-aea6-4323-b580-6e7a54f787f6 dc1cec1b-90c2-4493-9ea6-f89bb72c8721\n\n\nRunning scheduler (simulated time)...\n\n[Reminder for user_001] Please check your temperature again in 2 hours.\n[Reminder for user_001] Monitor your breathing and report any worsening symptoms in 6 hours.\n[Reminder for user_001] 24-hour follow-up: How are your symptoms today?\n\nExecuted 3 reminders\n\nDemo finished.\n\n\nRunning scheduler tests...\n[Scheduler] Scheduled reminder 17f9f07f-5f68-4c3c-8640-fc2faaacbddf in 0s\n[Scheduler] Scheduled reminder 0a241e55-2d29-409a-b604-5cca0a9087dd in 1s\n[Reminder for u1] Immediate reminder\n[Test] First run_pending executed: 1\n[Reminder for u1] Delayed reminder\n[Test] Second run_pending executed: 1\nScheduler tests passed.\n\n\nRunning advisor flow test...\n[Advisor] Received from tester: I have fever and cough for 1 day\n[MemoryAgent] Stored record 0e673d7c-8bdd-4203-ad44-b2224c5f9571 for user tester\n[MemoryAgent] Stored record 1c33de23-c353-469e-9960-8bb4944c0111 for user tester\n[Test] Advisor returned type: clarify\n[Advisor] Received from tester: I have chest pain and sweating\n[MemoryAgent] Stored record b88f6f5f-4ee7-453c-81d5-1bf33d74f8d9 for user tester\n[Advisor] Symptom tool result: {'diagnosis': 'Possible cardiac event', 'advice': 'seek emergency care', 'severity': 'high'}\n[Advisor] Validation: {'ok': False, 'reason': 'High-risk symptom detected (heuristic)', 'recommendation': 'escalate'}\n[MemoryAgent] Stored record 9bfa7bd6-30ab-4c1e-abf3-a9a8b0a78410 for user tester\n[Test] Advisor escalated as expected\nAdvisor tests passed.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}